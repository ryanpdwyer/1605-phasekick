"""
Compare the fits generated by the simple and convolution df vs t models.
Since the data workup doesn't take too long (~1 min vs 10-60 minutes for sampling),
workup the data fresh each time.
"""
from __future__ import division
from os import path
import os
from tqdm import tqdm
import numpy as np
import phasekick
import datetime
import phasekickstan as p
import time
from collections import OrderedDict
import lockin
import h5py

# Estimated run time 1:30 on rMBP 2012/
def get_filename_without_ext(path_):
    return path.splitext(path.split(path_)[1])[0]

def get_t_mu_sigma_df(trefm):
    t = trefm.tm
    mu_df = trefm.dfm
    sigma_df = np.std(trefm.df, axis=0, ddof=1)
    return t, mu_df, sigma_df

def save_workup(gr, params, t, mu_df, sigma_df, intensity, N):
    gr['t'] = t
    gr['mu_df'] = mu_df
    gr['sigma_df'] = sigma_df
    gr['N'] = N
    gr.create_group('workup_params')
    gr.create_group('experiment_params')
    for key, val in params.items():  # Save workup params
        gr['workup_params'][key] = val
    gr['experiment_params']['intensity'] = intensity



def arrays_to_stan_data(t, mu_df, sigma_df, Navg, params):
    df_std = sigma_df / Navg**0.5
    t = (t - params['t_delay']) * 1e3 # s to ms
    m = t <= 0
    y_neg = mu_df[m]
    offset = np.mean(y_neg)
    return {
    'y_neg': y_neg - offset,
    't': t[~m], # only positive times
    'N_neg': t[m].size,
    'y_neg_err': df_std[m],
    'y': mu_df[~m] - offset,
    'y_err': df_std[~m],
    'offset': offset,
    'N': t[~m].size
    }

def arrays_to_stan_conv(t, mu_df, sigma_df, Navg, params):
    """Generate the extended time array needed for convolution modeling."""
    fs = 1e6
    df_std = sigma_df / Navg**0.5
    Ndec = params['Ndec']
    dt = Ndec/fs
    fir = lockin.lock2(62000, params['fp'], params['fc'], fs)[::Ndec]*Ndec
    K = fir.size
    N = t.size
    NK1 = N + K - 1
    K2 = (K-1)/2
    t_offset = -dt*K2
    t = (t - params['t_delay'])
    t_eval = np.arange(NK1)*dt + t[0] + t_offset

    offset = np.mean(mu_df[t < 0.])

    return {
        't': t*1e3,
        't_eval': t_eval*1e3, 
        'N': N,
        'K': K,
        'kern': fir,
        'y_err': df_std,
        'y': mu_df - offset,
        'offset': offset}



def main(files, models, samples, chains, warmups):

    print("tr-EFM Signal averaged workup")
    print("=============================")
    print("\n")

    now = datetime.datetime.now()
    now_str = now.strftime("%y%m%d-%H%M")
    os.mkdir('2015-12-17/df/'+now_str)
    outdir = '2015-12-17/df/'+now_str

    # This looks pretty good. Perhaps decimate here too, then just have the
    # inputs to the stan curve fitting routine (plus workup params) saved?
    # Decision: Save Ndec here, but don't decimate yet.
    # 10x here
    filesdict = OrderedDict((
        ('2015-12-17/151217-200319-p1sun-df.h5',
            (0.1,
            {'fp': 1000,
             'fc': 4000,
             't_phase': -0.052,
             'ti': -0.005,
             'tf': 0.048,
              'Ndec': 62,
              't_delay': 5e-6}
              )
        ),
        ('2015-12-17/151217-205007-p3sun-df.h5',
            (0.3,
            {'fp': 1000,
             'fc': 4000,
             't_phase': -0.052,
             'ti': -0.002,
             'tf': 0.07,
             'Ndec': 62,
             't_delay': 5e-6}
             )
        ),
        ('2015-12-17/151217-211131-1sun-df.h5',
            (1.,
            {'fp': 3000,
             'fc': 12000,
             't_phase': -0.052,
             'ti': -1e-3,
             'tf': 5e-3,
             'Ndec': 4,
             't_delay': 5e-6}
            )
        ),
        ('2015-12-17/151217-234238-20sun-df-384.h5',
            (20.,
            {'fp': 4000,
             'fc': 15000,
             't_phase': -0.052,
             'ti': -400e-6,
             'tf': 2.8e-3,
             'Ndec': 1,
             't_delay': 4e-6}
             )
        ),
        ('2015-12-17/151218-003450-100sun-784.h5',
            (100.,
            {'fp': 4000,
             'fc': 15000,
             't_phase': -0.052,
             'ti': -350e-6,
             'tf': 1.4e-3,
             'Ndec': 1,
             't_delay': 3e-6}
             )
        )
    )
    )

    priorsdict = OrderedDict((
        ('151217-200319-p1sun-df',
        {
     'mu_df0': 0,
     'mu_df_inf': -13,
     'mu_tau': np.array([3.,15.]),
     'sigma_df0': 3,
     'sigma_df_inf': 5,
     'sigma_tau': np.array([5., 10.])}
        ),
        ('151217-205007-p3sun-df',
        {
     'mu_df0': 0,
     'mu_df_inf': -15,
     'mu_tau': np.array([1., 5.]),
     'sigma_df0': 3,
     'sigma_df_inf': 5,
     'sigma_tau': np.array([4, 15.])}
        ),
        ('151217-211131-1sun-df',
    {
     'mu_df0': 0,
     'mu_df_inf': -15,
     'mu_tau': np.array([0.5,2]),
     'sigma_df0': 3,
     'sigma_df_inf': 5,
     'sigma_tau': np.array([1, 2])}
        ),
        ('151217-234238-20sun-df-384',
    {
     'mu_df0': 0,
     'mu_df_inf': -20,
     'mu_tau': np.array([0.1,1]),
     'sigma_df0': 2.5,
     'sigma_df_inf': 7,
     'sigma_tau': np.array([0.5, 2])}
        ),
        ('151218-003450-100sun-784',
    {
     'mu_df0': 0,
     'mu_df_inf': -35,
     'mu_tau': np.array([0.1,1]),
     'sigma_df0': 2.5,
     'sigma_df_inf': 8,
     'sigma_tau': np.array([0.5, 2])}
        )
    )
    )





    dsets = sum(len(h5py.File(filename, 'r')['data'].keys()) for filename in files)

    subdict = {key: val for key, val in filesdict.items() if key in files}


    start = time.time()
    i = 0
    total = len(subdict)*len(models)
    for file, (intensity, params) in subdict.items():
        id_ = get_filename_without_ext(file)
        with h5py.File(file) as fh:

            trefm = phasekick.AverageTrEFM.from_group(fh['data'],
                                              params['fp'],
                                              params['fc'],
                                              params['t_phase'],
                                              params['ti'],
                                              params['tf'])

        t_, mu_df_, sigma_df_ = get_t_mu_sigma_df(trefm)

        Navg = trefm.t.shape[0]
        Ndec = params['Ndec']

        t = t_[::Ndec]
        mu_df = mu_df_[::Ndec]
        sigma_df = sigma_df_[::Ndec]

        priors = priorsdict[id_]
        for model, sample, chain, warmup in zip(models, samples, chains, warmups):
            print("Model: {}".format(model))
            out_path = path.join(outdir, id_+'-'+model+'.h5')

            if model == 'dflive_doub':
                data = arrays_to_stan_data(t, mu_df, sigma_df, Navg, params)
            elif model == 'dflive_conv_gauss':
                data = arrays_to_stan_conv(t, mu_df, sigma_df, Navg, params)
            else:
                raise ValueError("model must be 'dflive_doub' or 'dflive_conv_gauss'")

            pm = p.PhasekickModel(model, data, priors=priors)
            pm.run(chains=chain, iter=sample, warmup=warmup)
            pm.save(out_path)
            diff = time.time() - start
            i += 1
            print('{}/{} Elapsed: {:.1f} s, Remaining: {:.1f} s'.format(i, total, diff, diff/i*(total-i)
                ))




if __name__ == '__main__':
    main([
        # '2015-12-17/151217-234238-20sun-df-384.h5',
          '2015-12-17/151218-003450-100sun-784.h5'],
          ['dflive_doub', 'dflive_conv_gauss'], 
          [5000, 5000], chains=[2, 2], warmups=[2000, 2000])
